import json
import os
from src.vncorenlp_wrapper import VnCoreNLPWrapper
from src.cleaner import clean_comment_text # Assuming cleaner.py exists and clean_comment_text is defined
import sys
import os

def process_file(input_path, output_annotated_path, jar_path, annotators):
    # === B1: ƒê·ªçc d·ªØ li·ªáu g·ªëc ===
    if not os.path.exists(input_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {input_path}")
        return

    with open(input_path, "r", encoding="utf-8") as f:
        raw_data = json.load(f)

    # H·ªó tr·ª£ c·∫£ d·∫°ng 1 video l·∫ª
    if isinstance(raw_data, dict) and 'video_url' in raw_data:
        raw_data = [raw_data]

    print(f"üì• ƒê√£ ƒë·ªçc {len(raw_data)} video")

    # === B2: Kh·ªüi t·∫°o NLP duy nh·∫•t 1 l·∫ßn ===
    nlp = VnCoreNLPWrapper(
        jar_path=jar_path,
        annotators=annotators,
        models_dir="vncorenlp/models" # Ensure this path is correct relative to where you run the script
    )

    all_texts_to_annotate = []
    # Store references to where each text came from to map back results
    # Each item in this list will be a dict: {"comment_obj": ..., "type": "comment"|"reply"}
    text_references = [] 

    # === B2.1: Thu th·∫≠p t·∫•t c·∫£ vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch ===
    print("Collecting all comments and replies for batch processing...")
    for video in raw_data:
        if not isinstance(video, dict):
            print(f"‚ö†Ô∏è B·ªè qua ph·∫ßn t·ª≠ kh√¥ng h·ª£p l·ªá: {video}")
            continue

        for comment in video.get("comments", []):
            raw_text = comment.get("text", "")
            cleaned_text = clean_comment_text(raw_text)
            
            all_texts_to_annotate.append(cleaned_text)
            text_references.append({
                "source_type": "comment",
                "original_obj": comment # Keep a reference to the original comment object
            })

            for reply in comment.get("replies", []):
                reply_text = reply.get("text", "")
                cleaned_reply = clean_comment_text(reply_text)
                
                all_texts_to_annotate.append(cleaned_reply)
                text_references.append({
                    "source_type": "reply",
                    "original_obj": reply # Keep a reference to the original reply object
                })

    # === B2.2: G·ªçi NLP m·ªôt l·∫ßn duy nh·∫•t cho t·∫•t c·∫£ vƒÉn b·∫£n ===
    print(f"Calling VnCoreNLP to annotate {len(all_texts_to_annotate)} texts in batch...")
    # The annotate_batch method returns a list of lists of dictionaries
    # where each inner list corresponds to one of the input texts.
    all_annotations = nlp.annotate_batch(all_texts_to_annotate)
    print("Batch annotation complete.")

    # === B2.3: G·∫Øn k·∫øt qu·∫£ ph√¢n t√≠ch tr·ªü l·∫°i d·ªØ li·ªáu g·ªëc ===
    annotated_data = []
    
    if len(all_annotations) != len(all_texts_to_annotate):
        print(f"‚ùå C·∫£nh b√°o: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ ph√¢n t√≠ch ({len(all_annotations)}) kh√¥ng kh·ªõp v·ªõi s·ªë l∆∞·ª£ng vƒÉn b·∫£n ƒë·∫ßu v√†o ({len(all_texts_to_annotate)}). C√≥ th·ªÉ c√≥ l·ªói trong qu√° tr√¨nh ph√¢n t√≠ch.")
    
    # Iterate through the original references and attach their corresponding annotations
    for i, ref in enumerate(text_references):
        current_annotations = all_annotations[i] if i < len(all_annotations) else []
        current_cleaned_text = all_texts_to_annotate[i] # The cleaned text itself

        # Construct the annotated entry
        entry = {
            "text": current_cleaned_text,
            "username": ref["original_obj"].get("author", {}).get("username", ""),
            "likes_count": ref["original_obj"].get("likes_count", 0),
            "annotations": current_annotations # This is the key change!
        }
        annotated_data.append(entry)

    # === B3: Ghi ra file k·∫øt qu·∫£ ===
    os.makedirs(os.path.dirname(output_annotated_path), exist_ok=True)

    with open(output_annotated_path, "w", encoding="utf-8") as f:
        json.dump(annotated_data, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ ƒê√£ l∆∞u file ph√¢n t√≠ch: {output_annotated_path}")